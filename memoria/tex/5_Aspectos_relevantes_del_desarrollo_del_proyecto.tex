\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

% Este apartado pretende recoger los aspectos más interesantes del desarrollo del proyecto, comentados por los autores del mismo.
% Debe incluir desde la exposición del ciclo de vida utilizado, hasta los detalles de mayor relevancia de las fases de análisis, diseño e implementación.
% Se busca que no sea una mera operación de copiar y pegar diagramas y extractos del código fuente, sino que realmente se justifiquen los caminos de solución que se han tomado, especialmente aquellos que no sean triviales.
% Puede ser el lugar más adecuado para documentar los aspectos más interesantes del diseño y de la implementación, con un mayor hincapié en aspectos tales como el tipo de arquitectura elegido, los índices de las tablas de la base de datos, normalización y desnormalización, distribución en ficheros3, reglas de negocio dentro de las bases de datos (EDVHV GH GDWRV DFWLYDV), aspectos de desarrollo relacionados con el WWW...
% Este apartado, debe convertirse en el resumen de la experiencia práctica del proyecto, y por sí mismo justifica que la memoria se convierta en un documento útil, fuente de referencia para los autores, los tutores y futuros alumnos.

El desarrollo de este proyecto puede decirse que ha estado dividido principalmente en dos partes. La primera
fase estuvo relacionada con el diseño de la arquitectura, así como la elección del sistema gestor de bases de
datos. En la segunda fase, se diseñó todo lo relativo a la predicción de datos y a la elección de las
herramientas necesarias para dicha tarea.

\section{Primera fase}

Como ha sido mencionado en el párrafo anterior, en la primera fase se llevó a cabo el diseño de la
arquitectura del sistema, así como el desarrollo de los servicios que forman dicho sistema. Además,
se ha realizado una comparativa de diferentes sistemas gestores de bases de datos con el fin de elegir
el que mejor se adapte a nuestros requisitos.

%TODO AÑADIR REFERENCIA A SOCO

\subsection{Diseño de la arquitectura}

La arquitectura del sistema estudiado se representa en la figura \ref*{fig:Arquitectura}. El sistema
está formado por los siguientes sistemas software:
\begin{description}
    \item [AGV Coordinator] Es un servicio encargado de recibir la información enviada por los AGV a
        través de una conexión 5G/Wifi. Esta información está codificada como una cadena de bytes, que
        es decodificada y transformada a formato JSON. Estos mensajes son enviados al servicio 
        ``Receiver''. Este servicio no ha sido desarrollado como parte de este trabajo.
    \item [Simulator] Es, como su nombre en inglés indica, un servicio encargado de simular un AGV
        en caso de no disponer de AGV reales y sea necesario realizar pruebas.
    \item [Receiver] Este servicio recibe mensajes a través del protocolo UDP bien del ``AGV Coordinator''
        o bien del simulador, y se encarga de insertar dichos datos en la base de datos.
    \item [Database] Como su nombre indica, este servicio será la base de datos encargada de almacenar
        todos los datos recibidos.
\end{description}

\imagen{Arquitectura}{Diseño de la arquitectura}{1}

\subsection{Comparativa de Sistemas Gestores de Bases de Datos}

Lo primero a tener en cuenta a la hora de elegir un gestor de bases de datos es cuáles son nuestros
requisitos relacionados con el almacenamiento de los datos. Como hemos comentado anteriormente, el tiempo
juega un papel importante en los mensajes que enviamos, pues es importante saber cuando el valor de
una variable, como puede ser el nivel de la batería, fue reportado. Algunas de estas variables son
enviadas cada 10 o 20 milisegundos, por lo que una alta precisión temporal es necesaria.

\begin{table}[H]
    \begin{tabularx}{\textwidth}{l X}
        \toprule
        Requisito                 & Descripción \\
        \otoprule
        RF1:                & El sistema gestor de bases de datos debe soportar entradas con timestamp \\
        \rowcolor{gray!35}
        RF2:                & Los datos tienen que poder insertarse en cualquier momento \\
        RF3:                & El timestamp de las entradas de la base de datos ha de corresponder con el momento en el que dichos datos fueron creados en el AGV \\
        \rowcolor{gray!35}
        RF4:                & El sistema gestor de bases de datos debe poder soportar entradas con una precisión temporal en el rango de los milisegundos \\
        RNF1:                & El sistema gestor de base de datos debe ser de código abierto \\
        \rowcolor{gray!35}
        RNF2:                & EL sistema gestor de base de datos debe tener un buen soporte de Linux y Python \\
        \bottomrule
    \end{tabularx}
    \caption{Requisitos Funcionales (RF) y no Funcionales (RNF) de la base de datos}
    \label{tabla:req}
\end{table}

\subsubsection{Metodología de la comparación}

\paragraph{Sistemas de gestión de bases de datos bajo estudio}

Lo primero a tener en cuenta es el modelo de la base de datos que se va a utilizar, ya que tendrá una gran importancia
a la hora de decidir qué sistema de gestión de bases de datos se va a utilizar. Los siguientes modelos \cite{10.5555/3364297} han sido
tenidos en cuenta: 

\begin{itemize}
    \item Bases de datos relacionales: en estos sistemas, la información se almacena en relaciones. Una relación,
        definidas también como tablas, es una colección de tuplas, o filas. Las relaciones se definen por su nombre
        y un número fijo de atributos, o columnas, con tipos de datos fijos. Estos sistemas respetan las propiedades
        ACID (Atomicity, Consistency, Isolation y Durability), y tienen operaciones básicas definidas, como la selección,
        proyección y unión.
    \item Bases de datos de documentos: la principal característica de estas bases de datos es la organización de los datos
        de forma libre, sin seguir ningún esquema. Esto significa, por contrario que en las bases de datos relacionales,
        las entradas no poseen una estructura uniforme, las columnas pueden tener más de un valor e incluso pueden almacenar
        estructuras anidadas.
    \item Bases de datos de Clave-valor: son las bases de datos más simples y solo almacenan pares clave-valor. Normalmente
        no son factibles para aplicaciones complejas, pero normalmente presentan un gran rendimiento debido a su
        simplicidad.
    \item Motores de búsqueda: su uso principal es la búsqueda de datos, y son típicamente NoSQL, es decir, que no siguen
        un modelo relacional.
    \item Bases de datos de series temporales: estas bases de datos están optimizadas para almacenar series temporales \cite{influx:timeseries}.
        Aunque son típicamente NoSQL, bases de datos de series temporales relacionales existen.
\end{itemize}

Cualquiera de estos modelos permiten el manejo de información de series temporales, como la información que recibimos
de los AGV. Sin embargo, las bases de datos de series temporales están especializadas en este tipo de trabajos, por lo que
las hace perfectas para nuestras necesidades.

Como selección inicial, se han escogido los cinco sistemas gestores de bases de datos de series temporales más temporales
según el ranking DB-Engines \cite{dbengines:rankingTSDBMS}. Este ranking es utilizado en otros estudios, como \cite{10.1007/978-3-030-50426-7_28}.
Los sistemas gestores de bases de datos elegidos para comparar son:

\begin{itemize}
    \item \textbf{InfluxDB 2.6.1} Un sistema gestor de bases de datos de series temporales desarrollado por InfluxData. Su
        uso principal es el almacenamiento y obtención de series temporales, creadas en operaciones de monitoreo de IoT,
        información de sensores, etc.
    \item \textbf{kdb+ 4.0} Una base de datos de series temporales relacional desarrollado por KX, usado principalmente en
        negociación bursátil de alta frecuencia, para almacenar y para procesar datos a una alta velocidad.
    \item \textbf{Prometheus 2.43.0} Una base de datos de series temporales usada para el monitoreo de eventos y alarmas, que
        utiliza un modelo HTTP.
    \item \textbf{Graphite 1.1.10} Una herramienta que almacena, monitoriza y grafica series temporales numéricas.   
    \item \textbf{TimescaleDB 2.10.1} Una base de datos de código abierto, desarrollada como complemento a PostgreSQL con el
        fin de mejorar el rendimiento y análisis para series temporales.
\end{itemize}

Aunque este ranking solo mide la popularidad y ordena los sistemas en función de atributos sociales, es especialmente
útil para soluciones de código abierto, pues esto generalmente significa que está soportada por una comunidad activa
con muchos colaboradores involucrados en añadir nueva funcionalidad y corregir errores.

\paragraph*{Procedimiento de la comparación}
La comparación y el filtrado de los modelos seleccionados ha sido realizados en tres pasos secuenciales:
\begin{enumerate}
    \item Información general, soporte software y apoyo de la comunidad.
    \item Modelo de datos y especificaciones técnicas.
    \item Prueba de rendimiento.
\end{enumerate}

En los primeros dos pasos, los sistemas comparados que no cumplan los requisitos especificados en la tabla \ref{tabla:req}
han sido descartados. Después, con los sistemas restantes, se ha realizado una prueba de rendimiento con el fin de
tomar la decisión final. A su vez, esta prueba se divide en otras dos pruebas.

\imagen{DiagramaTests1}{Procedimiento de la prueba de inserción}{1}
\imagen{DiagramaTests2}{Procedimiento de la prueba de latencia}{1}

El primer test, (Figura \ref{fig:DiagramaTests1}) mide el uso de CPU y RAM del sistema cuando se insertan datos de forma
masiva, así como el tiempo tomado y el número de inserciones por segundo realizadas. En total, 300.000 entradas son enviadas,
formadas por los siguientes campos: timestamp, id del vehículo, batería, velocidad, posición en la coordenada x, posición
en la coordenada y, temperatura y voltaje. Para realizar la prueba de manera más realista, los datos se insertan en la
base de datos en tandas de 5.000. Para ello se almacenan primero en un buffer controlado por el servicio ``Receiver'', ya
que de esta manera se obtiene un mejor rendimiento que si se insertasen de uno en uno. Para medir el uso de CPU y de RAM
de la misma forma con todos los diferentes gestores, las medidas son tomadas de lo que reporta el estado del contenedor
de Docker en el que se ejecutan dichos sistemas.

En el segundo test (Figura \ref*{fig:DiagramaTests2}) se mide la latencia de inserción. Esto es, el tiempo que tarda
en estar disponible una entrada después de su inserción. Para esto, un script de Python, formado por dos hilos, ha sido creado.
El primero de esos hilos realiza la inserción en la base de datos y el otro intenta obtener dicha entrada en un bucle.
En el momento en el que dicha entrada se obtiene, se anota dicho tiempo y se resta del momento en le que se insertó
la entrada. Este test se realiza 200 veces y se hace una media con los resultados.

Cada test se realiza cinco veces para reducir la variabilidad, tomando la media de dichas ejecuciones como valor final.

\paragraph*{Métricas de la comparación} 
A continuación se detallan las métricas utilizadas para realizar la comparación.

% \textbf{Información general, soporte de software y comunidad}

Las métricas de información general analizan:
\begin{itemize}
    \item Organización: que organización o compañía es responsable del desarrollo y mantenimiento del sistema.
    \item Año de lanzamiento: en que año se lanzó inicialmente.
    \item Última versión: en que año se lanzó la última versión.
    \item Licencia: que tipo de licencia tiene el software: código abierto (OSS), o licencia comercial.
\end{itemize}
El indicador de rendimiento del soporte de software analiza:
\begin{itemize}
    \item Sistema Operativo: qué sistemas operativos se soportan.
    \item Soporte para Python: como el sistema está implementado en Python, nos interesa que el sistema tenga
        buen soporte de este lenguaje.
    \item Lenguaje de consultas: que lenguaje de consultas soporta el sistema.
    \item Plugins para aprendizaje automático: si el sistema soporta plugins que simplifiquen la predicción de nuevos
        datos.
\end{itemize}
La comparación del soporte de la comunidad contiene:
\begin{itemize}
    \item Número de estrellas del repositorio de GitHub: como forma de medir su popularidad.
    \item Pull requests: número de pull requests enviadas en el último mes.
    \item Pull requests aceptadas: número de pull requests aceptadas en el último mes.
    \item Issues: número de issues creados en el último mes.
    \item Issues cerrados: número de issues cerrados en el último mes.
\end{itemize}
Estos cuatro últimos campos se usarán para comparar que comunidad es más activa.

% \textbf{Modelo de datos e información técnica}

El indicador de rendimiento del modelo de datos compara:
\begin{itemize}
    \item Modelo de datos: que modelo concreto implementa cada sistema.
    \item Esquema: un esquema puede verse como una plantilla que define como se almacena la información. Este campo
        compara si la organización de los datos es estricta (esquema fijo) o no (esquema libre).
    \item Índices secundarios: si el sistema soporta índices secundarios para un mejor rendimiento de consultas o no.
    \item Precisión temporal: unidad mínima de tiempo que puede tener una entrada.
\end{itemize}

El indicador de rendimiento de información técnica se compone de los siguientes campos:
\begin{itemize}
    \item Scripts de servidor: si el sistema es capaz de ejecutar scripts en el servidor o no.
    \item Método de partición: si se soportan o no métodos de partición para una mayor escalabilidad.
    \item Replicación: que métodos de replicación soporta.
    \item Consistencia: si la información escrita es consistente o no.
    \item Conformidad con ACID: si el sistema sigue los principios ACID o no.
    \item Concurrencia: si el sistema soporta accesos concurrentes o no.
    \item Durabilidad: si la información es persistente, incluso si falla.
    \item Método de inserción: si la información se introduce mediante una consulta de inserción o extrayendo los
        datos de un endpoint de forma periódica.
\end{itemize}

% \textbf{Análisis de rendimiento}

Por último, el análisis de rendimiento compara:
\begin{itemize}
    \item Tiempo de inserción: tiempo que se tarda en hacer la prueba de inserción en segundos.
    \item Tasa de transferencia: número de inserciones por segundo.
    \item Uso de la CPU: uso de la CPU del contenedor de Docker en el que se ejecuta base de datos durante 
        la primera prueba.
    \item Uso de RAM: uso de RAM del contenedor de Docker en el que se ejecuta la base de datos durante la
        primera prueba.
    \item Latencia: tiempo que tarda en ejecutarse la segunda prueba en milisegundos.
\end{itemize}

\subsubsection{Experimentos y resultados}

\begin{table}[H]
    \begin{center}
        \begin{adjustbox}{max width=\textwidth}
            \rowcolors{2}{gray!35}{}
            \begin{tabular}{l c c c c}
                \toprule
                Systems & Organization & Launch year & Latest version & License \\
                \otoprule
                InfluxDB    & InfluxData & 2013 & 2023 & OSS \\
                db+        & Kx Systems & 2000 & 2020 & Comercial \\
                Prometheus  & -          & 2015 & 2023 & OSS \\
                Graphite    & -          & 2006 & 2022 & OSS \\
                TimescaleDB & Timescale  & 2017 & 2023 & OSS \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
        \caption{Comparativa de información general}
        \label{tabla:gisgbd}
    \end{center}
\end{table}

\paragraph{Información general (Tabla \ref*{tabla:gisgbd})} Solo software de código abierto será considerado en este
trabajo. Aunque kdb+ tiene una versión de 32 bits, no se usará y no volverá a aparecer en las siguientes comparaciones.
Por esta razón también, solo las características de la ``Comunity Edition'' de InfluxDB serán utilizadas en dichas
comparaciones, y características de la ``Enterprise Edition'', que no es de códigp abierto, no se tendrán en cuenta.

\begin{table}[H]
    \begin{center}
        \begin{adjustbox}{max width=\textwidth}
            \begin{tabular}{l c c c c}
                \toprule
                System & OS & Python & Query language & ML Plugins\\
                \otoprule
                & Linux &                       &  \\
                \multirow{-2}{*}{InfluxDB} & OS x  & \multirow{-2}{*}{Sí} & \multirow{-2}{*}{Flux and InfluxQL} & \multirow{-2}{*}{Loud ML} \\
                \rowcolor{gray!35}
                                            & Linux   &                        & & \\
                \rowcolor{gray!35}
                \multirow{-2}{*}{Prometheus} & Windows & \multirow{-2}{*}{Sí}  & \multirow{-2}{*}{PromQL} & \multirow{-2}{*}{No}\\
                                        & Linux &                       &  & \\
                \multirow{-2}{*}{Graphite} & Unix  & \multirow{-2}{*}{Sí}  & \multirow{-2}{*}{No} & \multirow{-2}{*}{No} \\
                \rowcolor{gray!35}
                                            & Linux   &                             & & \\
                \rowcolor{gray!35}
                                            & OS X    &                             & & \\
                \rowcolor{gray!35}
                \multirow{-3}{*}{TimescaleDB} & Windows & \multirow{-3}{*}{Sí} & \multirow{-3}{*}{SQL} & \multirow{-3}{*}{No} \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
        \caption{Soporte software}
        \label{tabla:sssgbd}
    \end{center}
\end{table}

\paragraph{Soporte software (Tabla \ref*{tabla:sssgbd})} Todos los sistemas soportan Linux y Python, el sistema operativo 
y lenguaje utilizados. Solo Graphite no tiene un lenguaje de consultas definido, aunque se pueden realizar utilizando lo que 
llaman Funciones \cite{graphite-functions}. Sólo InfluxDB soporta plugins para aprendizaje automático. Otros sistemas como
TimescaleDB proveen documentación para realizarlo de forma externa en lenguajes como Python o R \cite{timescale-forecasting}.

\begin{table}[H]
    \begin{center}
        \begin{adjustbox}{max width=\textwidth}
            \rowcolors{2}{gray!35}{}
            \begin{tabular}{l c c c c c c}
                \toprule
                Sistemas & Estrellas GitHub & Pull requests & Pull requests aceptadas & Issues & Issues cerrados \\
                \otoprule
                InfluxDB    & 25.2k & 26 & 22 & 37 & 13 \\
                Prometheus  & 47.4k & 75 & 53 & 42 & 20\\
                Graphite & 5.6k & 0 & 0 & 0 & 0 \\
                TimescaleDB & 14.7k & 105 & 83 & 67 & 46 \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
        \caption{Soporte de la comunidad}
        \label{tabla:cssgbd}
    \end{center}
\end{table}

\paragraph*{Soporte de la comunidad (Tabla \ref*{tabla:cssgbd})} Como muestra la tabla, todos los proyectos son muy
activos a excepción de Graphite.

\begin{table}[H]
    \begin{center}
        \begin{adjustbox}{max width=\textwidth}
            \begin{tabular}{l c c c c c}
                \toprule
                \multirow{2}{*}{Sistema} & \multirow{2}{*}{Modelo} & \multirow{2}{*}{Esquema} & \multirow{2}{*}{Tipado} & Índice & Precisión\\
                &&&& secundario & temporal \\
                \otoprule
                &&& Numéricos && \\
                \multirow{-2}{*}{InfluxDB}    & \multirow{-2}{*}{Multidimensional} & \multirow{-2}{*}{Libre} & y strings & \multirow{-2}{*}{No} & \multirow{-2}{*}{Nanosegundos} \\
                \rowcolor{gray!35}
                Prometheus  & Multidimensional & Sí & Numéricos & No & Milisegundos \\
                Graphite    & Key-Value & Sí & Numéricos & No & Segundos \\
                \rowcolor{gray!35}
                TimescaleDB & Relacional & Sí & Tipos SQL & Sí & Nanosegundos \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
        \caption{Comparativa del modelo de datos}
        \label{tabla:dmsgbd}
    \end{center}
\end{table}

\paragraph*{Comparación del modelo de datos (Tabla \ref*{tabla:dmsgbd})} Tanto InfluxDB como Prometheus utilizan un modelo 
multidimensional. Este modelo puede verse como un modelo clave-valor multidimensional: las entradas de datos están formados 
por un campo que describe la información almacenada (``nombre de la métrica'' para Prometheus y ``medida'' para InfluxDB) 
y un set de pares clave-valor asociados con un timestamp. La principal diferencia es que las entradas en el modelo de InfluxDB 
están formados por la medida, un set de etiquetas y un set de valores, en vez de solo un set de pares clave-valor. 
Estas etiquetas guardan metadatos en forma de cadenas de caracteres, son opcionales y están indexados, mientras que el set de 
valores guardan la información, no están indexados y están asociados con un timestamp.

Graphite agrega los datos de manera automática en ventanas de un segundo o más. Este comportamiento no es el deseado 
para nuestras necesidades, ya que se requiere almacenar todos los datos enviados.

\begin{table}[H]
    \begin{center}
        \begin{adjustbox}{max width=\textwidth}
            \begin{tabular}{l c c c c}
                \toprule
                Sistema & InfluxDB & Prometheus & Graphite & TimescaleDB \\
                \otoprule
                Scripts del servidor & No & No & No & Sí \\
                \rowcolor{gray!35}
                Particionamiento & No & Sharding & No & Sí \\
                Replicación & No & Sí & No & Sí \\
                \rowcolor{gray!35}
                Consistencia & Eventual & No & No & Innmediata \\
                ACID& No & No & No & Sí \\
                \rowcolor{gray!35}
                Concurrencia & Sí & Sí & Sí & Sí \\
                Durabilidad & Sí & Sí & Sí & Sí \\
                \rowcolor{gray!35}
                Permisos                   & Permisos vía    &                      &                      & Derechos \\
                \rowcolor{gray!35}
                de usuario & cuentas & \multirow{-2}{*}{No} & \multirow{-2}{*}{No} & estandar SQL \\
                Método inserción & Push & Pull & Push & Push \\
                \bottomrule
            \end{tabular}
        \end{adjustbox}
        \caption{Comparativa de información técnica}
        \label{tabla:tisgbd}
    \end{center}
\end{table}

\paragraph*{Comparativa información técnica (Tabla \ref*{tabla:tisgbd})} En InfluxDB, la consistencia es eventual. Según
la documentación, se prioriza el rendimiento de lectura y escritura antes que una fuerte consistencia. Se asegura, sin 
embargo, que la información es eventualmente consistente \cite{influx:consistency}.

En bases de datos típicas, la información se inserta a través de algún tipo de consulta desde fuera. Por otro lado, 
Prometheus escucha a un endpoint en el que se publican los datos y se obtienen en intervalos fijos de tiempo. Esto 
significa que la inserción solo ocurrirá cuando Prometheus escuche a dicho endpoint, por lo que la información no se 
puede insertar en cualquier momento. Un método más típico existe, pero no es recomendado y no es posible especificar 
timestamps \cite{prom:pushgateway}.

Solo InfluxDB y TimescaleDB cumplen todos los requisitos, ya que Graphite agrega los datos en ventanas de 1 segundo,
haciendo imposible obtener datos de un momento concreto, y la forma de inserción de Prometheus le hace incompatible 
con nuestras necesidades, ya que es necesario poder insertar datos en cualquier momento. Por esto, solo estos dos
sistemas se compararán en la prueba de rendimiento.

\paragraph*{Análisis del rendimiento} La prueba se realizó con un procesador AMD Ryzen 5 3600 y 32 GB de RAM. Ya que 
este modelo de CPU tiene 12 hilos, el uso de la CPU puede ser tan alto como 1200\% (Uso CPU = Hilos * 100). Los resultados
de esta prueba se muestran en la tabla \ref*{tabla:ptsgbd}.

\tablaSmallFija{Resultados de la prueba de rendimiento}{l c c}{ptsgbd}{
System & InfluxDB & TimescaleDB\\
}{
    Tiempo inserción (s) & 24.13 & \textbf{1.16} \\
    Tasa inserción (I/s) & 12432.66 & \textbf{258620.69} \\
    Uso CPU (\%) & \textbf{15.05} & 55.32 \\
    Uso RAM (MB) & \textbf{219.85} & 373.73 \\
    Latencia (ms) & 3.37 & \textbf{0.22} \\
}

Como se puede observar, InfluxDB es más lento en todos las pruebas que TimescaleDB, pero este último utiliza más 
recursos del sistema. Si en un futuro es necesario escalar InfluxDB puede ser mejor opción, ya que un menor uso de 
recursos suele significar un menor coste. Sin embargo, TimescaleDB es más flexible, ya que al estar basado en PostgreSQL 
tiene todas sus características. Cualquiera de estos dos sistemas puede ser perfectamente usado según los requisitos marcados.

\subsubsection{Elección}

Al final, el sistema gestor de bases de datos escogido ha sido InfluxDB. Aunque sea más lento que TimescaleDB, tiene
una velocidad lo suficientemente buena, y al consumir menos recursos la hace una opción más barata en caso de que 
esta solución se aplique comercialmente.

Otro motivo de peso para elegir InfluxDB es que viene por defecto con una interfaz web llamada Chronograf 
(Figura \ref*{fig:interfaz}) en la que se puede manejar la base de datos, crear gráficas, establecer alarmas, etc.

\imagen{interfaz}{Interfaz Chronograf}{1}

\subsection{Desarrollo de los servicios}

Una vez diseñada la arquitectura y el sistema gestor de bases de datos escogido, se procedió a desarrollar los
sistemas definidos.

\subsubsection{Simulator}
Inicialmente, no disponía de datos reales del AGV, por lo que la primera versión (Figura \ref*{fig:v1sim}) simplemente generaba datos aleatorios
con campos aleatorios, y los enviaba al nodo ``Receiver'' por UDP utilizando el puerto 5004.

Después, se intentó desarrollar un simulador capaz de, valga la redundancia, simular el comportamiento de un AGV. Sin
embargo, una vez dispuse de datos reales del AGV, esta idea se descartó, pues simular dicha información de forma
precisa iba a ser demasiado complejo, y se escapa del objetivo de este proyecto. Por tanto, se decidió simular el
comportamiento del AGV leyendo los datos de un CSV (Figura \ref*{fig:v2sim}) obtenido a partir de uno real.

\begin{figure}
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics*[width=0.5\textwidth]{v1sim}
        \caption{Generación aleatoria}
        \label{fig:v1sim}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics*[width=\textwidth]{v2sim}
        \caption{Generación por CSV}
        \label{fig:v2sim}
    \end{subfigure}
    \begin{subfigure}[b]{0.7\textwidth}
        \centering
        \includegraphics*[width=\textwidth]{sim}
        \caption{Versión final}
        \label{fig:sim}
    \end{subfigure}
    \caption{Diagramas de flujo del simulador}
    \label{fig:diagsim}
\end{figure}

Por último, en la versión final, se unificaron los dos procedimientos, de forma que el comportamiento del simulador
se decide según lo especificado en un archivo de configuración.

\subsubsection{Receiver}

El funcionamiento del nodo ``Reciever'' es muy simple (Figura \ref*{fig:recv}): escucha el puerto UDP 5004, y cuando recibe información, la inserta 
en la base de datos. Inicialmente, el servicio intentará conectarse a la base de datos. Si esta conexión falla un número
determinado de veces, el servicio fallará informando de que la conexión no ha podido realizarse.

\imagen{recv}{Diagrama de flujo del servicio ``Reciever''}{0.5}

\section{Segunda fase}

La segunda fase se centró en el desarrollo y diseño del servicio de predicción de nuevos datos.
Se ha realizado un análisis comparativo de diferentes modelos predictivos, así como un análisis
de los datos recibidos por el AGV para hacer la mejor elección.

\subsection{Modificación de la arquitectura}

Ya que se ha pretendido desarrollar una arquitectura lo más modular posible, la predicción de la 
información se realiza desde un nuevo servicio. Por ende, la arquitectura modificada queda de la 
siguiente manera:

\imagen{Arquitectura2}{Arquitectura final}{1}

Este nuevo servicio se conecta directamente a la base de datos. Con esta conexión, obtiene la 
información necesaria para hacer las predicciones, y una vez hechas se insertan en la base de datos 
para poder ser visualizadas en Chronograf (Figura \ref{fig:interfaz}).

\subsection{Análisis de los datos}

Antes de hacer nada relativo a la predicción de los datos, necesitamos conocer que datos tenemos y cuáles 
queremos predecir. Del AGV recibimos los siguientes datos:
\begin{itemize}
    \item Tiempo: tiempo que ha pasado en segundos desde que se inicia el AGV.
    \item Encoder derecho: valor del codificador de la rueda derecha. Cuando el AGV avanza este valor se
        incrementa, y cuando retrocede se decrementa.
    \item Encoder izquierdo: igual al anterior, pero con la rueda izquierda.
    % TODO \item CorrienteL 
    % TODO \item CorrienteH
    % TODO \item Medida bateria
    \item Error de guiado: distancia que el AGV está desviado de la banda magnética por la que se guía.
    \item Consigna de velocidad derecha: valor de la velocidad enviado a la rueda derecha.
    \item Consigna de velocidad izquierda: similar al anterior pero con la rueda izquierda.
    % TODO \item Display
\end{itemize}

Cabe mencionar que, como los encoders derecho e izquierdo no nos muestran directamente la velocidad de sus 
ruedas, antes hay que preprocesar dichos datos, restando cada valor con su anterior, obteniendo así el dato de la 
velocidad.

Nuestra intención es realizar una predicción de los valores encoder derecho y encoder izquierdo para poder 
compararlos con los obtenidos y detectar posibles errores. Para ello, utilizamos valores anteriores de los 
mismos datos, así como los valores de las consignas de velocidad derecha e izquierda, pues su correlación 
es muy alta. Para predecir los valores derechos, y viceversa, se usan también los valores izquierdos, pues aunque su 
correlación no sea tan alta, también están correlacionados.
Ya que estos datos se mandan en intervalos de tiempo irregulares, el primer paso es agruparlos en ventanas de 200 milisegundos. 
Esto es así porque para realizar las predicciones es necesario que los datos de la serie temporal estén distribuidos 
de manera uniforme.

Las pruebas realizadas a continuación han sido realizadas únicamente con el encoder derecho, pues al ser muy similar 
al encoder izquierdo se van a obtener resultados prácticamente idénticos en los dos casos, por lo que no merece 
la pena realizar las pruebas sobre los dos datos.

\subsection{Comparativa de modelos de predicción}

% TODO COMPARATIVA MODELOS SOLO QUEDA REALIZAR PRUEBAS
Los modelos elegidos para la comparación son aquellos brevemente explicados en la sección de conceptos teóricos:
\begin{itemize}
    \item ARIMA.
    \item TCN.
    \item N-HiTS.
    \item Transformer Model.
\end{itemize}

Estos modelos han sido comparados usando las siguientes métricas, también explicados en la sección de conceptos teóricos:
\begin{itemize}
    \item MAE 
    \item MASE 
    \item DTW
\end{itemize}

Se van a hacer tres tipos de comparaciones: una comparación univariante en la que solo se prediga un valor, 
una comparación univariante con covariables en la que solo se prediga un valor, pero se utilicen otros como entrada y 
una comparación multivariante en la que se predigan todos los valores utilizados como entrada.


Para realizar la comparación, excepto en el caso de ARIMA que es un modelo estadístico que no usa redes neuronales, 
se entrena el modelo durante 200 épocas y se realizan varias predicciones: una 200 milisegundos a futuro, otra 
1 segundo a futuro y otra 10 segundos a futuro. Este procedimiento se realiza cinco veces y se calcula la media 
de las métricas como valor final.

\subsubsection*{Comparativa inicial}

Una primera comparativa ha sido realizada con los parámetros por defecto que Darts provee de dichos modelos. 
Los únicos parámetros especificados han sido la longitud de los datos de entrada y la longitud de los datos de salida 
en aquellos modelos que lo permitan. Se ha especificado una longitud de entrada de 60 valores 
(correspondiente a 12 segundos), y una longitud de salida de 10 valores (2 segundos). En los casos con covariables,
se ha modificado la longitud de salida para la prueba de predicción de 10 segundos, pues, al no hacer la predicción 
de dichas covariables solo se puede hacer una predicción a futuro, ya que no se poseen los datos para realizar más.

\begin{table}[H]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{c | c c c | c c c | c c c}
            \toprule
            & \multicolumn{3}{c | }{Univariante} & \multicolumn{3}{c | }{Covariante} & \multicolumn{3}{c}{Multivariante} \\
            Tiempo & 0.2 & 1 & 10 & 0.2 & 1 & 10 & 0.2 & 1 & 10 \\
            \otoprule
            ARIMA & \textbf{65.09} & \textbf{161.66} & 1907.52 & - & - & - & - & - & - \\
            TCN & 1211.47 & 1288.55 & 2394.42 & 1190.54 & 1296.46 & 2830.52 & 1321.59 & 1313.16 & 2350.11 \\
            N-HiTS & 135.49 & 353.99 & 1925.49 & 729.24 & 802.57 & 1736.21 & 446.28 & 478.43 & 1045.04 \\
            Transformer & 213.79 & 426.78 & 2127.07 & 155.12 &  \textbf{188.81} & \textbf{542.05} & 167.89 & 222.10 & 719.10 \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
    \caption{MAE de la comparación inicial}
    \label{tab:mae_inicial}
\end{table}

\begin{table}[H]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{c | c c c | c c c | c c c}
            \toprule
            & \multicolumn{3}{c | }{Univariante} & \multicolumn{3}{c | }{Covariante} & \multicolumn{3}{c}{Multivariante} \\
            Tiempo & 0.2 & 1 & 10 & 0.2 & 1 & 10 & 0.2 & 1 & 10 \\
            \otoprule
            ARIMA & \textbf{0.30} & \textbf{0.74} & 8.83 & - & - & - & - & - & - \\
            TCN & 5.60 & 5.96 & 11.08 & 5.51 & 6.00 & 13.10 & 6.11 & 6.08 & 10.88 \\
            N-HiTS & 0.62 & 1.63 & 8.91 & 3.37 & 3.71 & 8.03 & 2.06 & 2.21 & 4.83 \\
            Transformer & 0.98 & 1.97 & 9.84 & 0.71 & 0.87 & \textbf{2.50} & 0.77 & 1.02 & 3.32 \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}    
    \caption{MASE de la comparación inicial}
    \label{tab:mase_inicial}
\end{table}

\begin{table}[H]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{c | c c c | c c c | c c c}
            \toprule
            & \multicolumn{3}{c | }{Univariante} & \multicolumn{3}{c | }{Covariante} & \multicolumn{3}{c}{Multivariante} \\
            Tiempo & 0.2 & 1 & 10 & 0.2 & 1 & 10 & 0.2 & 1 & 10 \\
            \otoprule
            ARIMA & \textbf{65.09} & \textbf{128.89} & 1345.79 & - & - & - & - & - & - \\
            TCN & 1211.47 & 1288.55 & 1193.36 & 1190.54 & 1296.46 & 1945.16 & 1321.59 & 1313.16 & 1217.87 \\
            N-HiTS & 135.49 & 347.68 & 852.25 & 729.24 & 802.57 & 1097.82 & 446.28 & 459.72 & 580.90 \\
            Transformer & 213.79 & 419.45 & 587.69 & 155.12 & 174.44 & \textbf{197.11} & 167.89 & 207.46 & 281.88 \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
    \caption{DTW de la comparación inicial}
    \label{tab:dtw_inicial}
\end{table}

ARIMA solo soporta modelos univariantes, por lo que no puede ser probado en los ejemplos covariantes y multivariantes.

\subsubsection*{Optimización de los hiperparámetros}

Los resultados del apartado anterior son mejorables. Para ello, es necesario encontrar los parámetros de los 
modelos que mejor se ajusten a nuestros datos. Esto, sin embargo, no es una tarea simple, pues existe una enorme 
cantidad de ellos para los modelos que utilicen redes neuronales (TCN, N-HiTS y Transformer). Para la optimización 
de dichos modelos se ha utilizado una herramienta llamada Optuna. Esta herramienta prueba cada modelo durante 
varias horas probando diferentes combinaciones de hiperparámetros de manera automática.

Para el caso de ARIMA la optimización es más simple, pues, como se ha explicado en el apartado de conceptos 
teóricos solo tiene tres parámetros. Además, dichos parámetros pueden optimizarse de manera analítica, utilizando 
los gráficos de autocorrelación y autocorrelación parcial. El primero de estos muestra como de relacionado está 
un valor de la serie temporal con sus anteriores, mientras que el segundo muestra la correlación con el valor 
inmediatamente anterior al actual.

\imagen{acf}{ACF del encoder derecho}{1}
\imagen{pacf}{PACF del encoder derecho}{1}

Como podemos ver, el valor del ACF decrementa, pero de manera muy lenta, lo que nos indica que necesitamos 
por lo menos un orden de diferenciación, por lo que el parámetro d será por lo menos de 1. 

\imagen{acf_dif2}{ACF del encoder derecho después de diferenciar}{1}
\imagen{pacf_dif2}{PACF del encoder derecho después de diferenciar}{1}

Se puede ver también como a partir del elemento 16 no se aprecian valores significativos, por lo que el valor del 
parámetro p será 16. Estas observaciones nos indican a pensar que el modelo es ARIMA(p, d, 0), ya que se cumplen 
dichas condiciones:
\begin{itemize}
    \item El ACF decae de manera exponencial.
    \item En el PACF, hay un valor significativo a partir del valor p, pero ninguno más adelante.
\end{itemize}

Por todo esto, el modelo ARIMA que mejor se adapta a nuestro caso es ARIMA(16, 1, 0).

\begin{table}[H]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{c | c c c | c c c | c c c}
            \toprule
            & \multicolumn{3}{c | }{Univariante} & \multicolumn{3}{c | }{Covariante} & \multicolumn{3}{c}{Multivariante} \\
            Tiempo & 0.2 & 1 & 10 & 0.2 & 1 & 10 & 0.2 & 1 & 10 \\
            \otoprule
            ARIMA & 38.96 & 133.31 & 1904.27 & - & - & - & - & - & - \\
            TCN &  &  &  &  &  &  &  &  &  \\
            N-HiTS &  &  &  &  &  &  &  &  &  \\
            Transformer &  &  &  &  &  &  &  &  &  \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
    \caption{MAE de la comparación con optimización}
    \label{tab:mae_opt}
\end{table}

\begin{table}[H]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{c | c c c | c c c | c c c}
            \toprule
            & \multicolumn{3}{c | }{Univariante} & \multicolumn{3}{c | }{Covariante} & \multicolumn{3}{c}{Multivariante} \\
            Tiempo & 0.2 & 1 & 10 & 0.2 & 1 & 10 & 0.2 & 1 & 10 \\
            \otoprule
            ARIMA & 0.18 & 0.61 & 8.81 & - & - & - & - & - & - \\
            TCN &  &  &  &  &  &  &  &  &  \\
            N-HiTS &  &  &  &  &  &  &  &  &  \\
            Transformer &  &  &  &  &  &  &  &  &  \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}    
    \caption{MASE de la comparación con optimización}
    \label{tab:mase_opt}
\end{table}

\begin{table}[H]
    \centering
    \begin{adjustbox}{max width=\textwidth}
        \begin{tabular}{c | c c c | c c c | c c c}
            \toprule
            & \multicolumn{3}{c | }{Univariante} & \multicolumn{3}{c | }{Covariante} & \multicolumn{3}{c}{Multivariante} \\
            Tiempo & 0.2 & 1 & 10 & 0.2 & 1 & 10 & 0.2 & 1 & 10 \\
            \otoprule
            ARIMA & 38.96 & 110.17 & 1606.00 & - & - & - & - & - & - \\
            TCN &  &  &  &  &  &  &  &  &  \\
            N-HiTS &  &  &  &  &  &  &  &  &  \\
            Transformer &  &  &  &  &  &  &  &  &  \\
            \bottomrule
        \end{tabular}
    \end{adjustbox}
    \caption{DTW de la comparación con optimización}
    \label{tab:dtw_opt}
\end{table}

\subsection{Desarrollo del servicio}

% TODO DESARROLLO DEL SERVICIO

Como se puede ver en la siguiente imagen (Figura \ref{fig:diagrama_forecast}), este servicio carga un modelo desde 
un archivo o bien lo entrena desde cero. Para poder entrenar dicho modelo, se necesita que la base de datos ya tenga 
datos cargados, por lo que la rutina de entrenamiento espera algunos minutos antes de empezar a entrenar para que 
haya los datos necesarios para poder realizar dicha tarea.

Cuando se predicen los datos, estos son insertados a un ``bucket'' de la base de datos diferente al que están los datos.
Este ``bucket'' tiene un periodo de retención bajo. Esto significa que los datos insertados se eliminan después 
de cierto tiempo. Esto tiene sentido, ya que no nos interesa guardar las predicciones antiguas.

\imagen{diagrama_forecast}{Diagrama del servicio de predicción.}{0.8}

\section{Puesta en marcha}
% TODO PUESTA EN MARCHA (REVISAR TITULO)