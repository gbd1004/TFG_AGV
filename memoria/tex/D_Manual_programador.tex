\apendice{Documentación técnica de programación}

\section{Introducción}

En este apartado del anexo se detallará la organización de los repositorios del proyecto, así
como un manual de programador, una guía de instalación y ejecución del mismo y las pruebas realizadas
al sistema.

\section{Estructura de directorios}

La organización de los directorios queda definida de la siguiente manera:

\dirtree{%
.1 memoria.
.2 build.
.2 img.
.2 tex.
}

El directorio memoria guarda todos los archivos relacionados con la memoria y estos anexos. En 
el subdirectorio build se encuentran los archivos pdf finales, en img se encuentran las imágenes 
utilizadas y en tex se guardan los archivos de LaTeX de cada uno de las secciones de la memoria y 
los anexos.

\dirtree{%
.1 prototipos.
.2 datos.
.2 forecasting.
.2 graphite.
.2 influxdb.
.2 mongo.
.2 prometheus.
.2 sqlite.
.2 timescaledb.
}

En el directorio prototipos se guardan todos los prototipos creados durante la realización del 
proyecto. Es código realizado de forma rápida con el fin de adecuarme al uso e investigar la funcionalidad
básica de cada una de las diferentes herramientas consideradas.

\dirtree{%
.1 rendimiento.
.2 database.
.2 forecast.
}

En el directorio de rendimiento se guarda todo el código de las pruebas de rendimiento realizadas 
para la comparación de las bases de datos y modelos de predicción. En el subdirectorio de 
forecast se encuentra también el código utilizado para la optimización de los hiperparámetros de 
los modelos comparados.

\dirtree{%
.1 services.
.2 forecasting.
.3 cpu.
.3 gpu.
.3 model.
.3 src.
.2 reciever.
.3 src.
.2 simulator.
.3 src.
.3 data.
}

En el directorio de servicios se encuentra todo el código y archivos de configuración de cada 
uno de los servicios desarrollados en este proyecto. El código se encuentra en el directorio
``src'' de dentro de cada uno de los subdirectorios de cada servicio. En la carpeta ``data'',
dentro del directorio del simulador, se guardan los archivos csv utilizados para leer desde 
este servicio. En los subdirectorios ``cpu'' y ``gpu'' dentro del servicio de predicción se 
encuentran los Dockerfiles de las respectivas versiones de este servicio.

\section{Manual del programador}

En esta sección se detallarán todas las dependencias necesarias para posibles futuros desarrollos, así como
los pasos necesarios para realizar dicha tarea. Este manual está pensado para el desarrollo sobre GNU/Linux,
más específicamente a cualquier distribución derivada de Debian como puede ser Ubuntu o Mint.

\subsection{Entorno de desarrollo}

Como todos los servicios se ejecutan de manera virtualizada dentro de contenedores de Docker, técnicamente las 
únicas herramientas esenciales son las siguientes:
\begin{itemize}
    \item Git: para clonar el repositorio.
    \item Docker: para crear los contenedores de cada servicio.
    \item Docker compose: para ejecutar todos los contenedores creados.
    \item Nvidia-docker: en caso de realizar el entrenamiento del modelo usando GPU.
\end{itemize}

Desarrollar de esta manera no es nada práctico, por lo que las dependencias necesarias para trabajar adecuadamente son, 
a demás de las anteriores:
\begin{itemize}
    \item Python 3.10
    \item InfluxDB 2.6.1
    \item Darts
\end{itemize}

\subsubsection{Git}

Git es necesario para poder interactuar con el repositorio, pues nos permite clonarlo, crear nuevas ramas,
subir cambios, etc. Git puede ser encontrado en \cite{git}.


\subsubsection{Docker}

Docker \cite{docker-pag} es una herramienta que permite ejecutar procesos en contenedores. Un contenedor es un proceso aislado del 
resto del sistema, similar a una máquina virtual. Para ello, se crea lo que se conoce como imagen, que es una especie 
de plantilla del contenedor. Esta imagen contiene el sistema de ficheros del contenedor y todas las dependencias 
necesarias para ejecutar los procesos de este.

Gracias a esto, conseguimos que el sistema sea portable, pudiendo ser ejecutado en cualquier sistema que soporte 
Docker. Gracias también a Docker se simplifica mucho el despliegue del sistema, pues todas las dependencias 
se instalan en el sistema de ficheros especificado en la imagen.

Para definir estas imágenes se utiliza un archivo llamado ``Dockerfile''. Por ejemplo, este es el Dockerfile del 
servicio simulador:
\begin{lstlisting}
FROM python:3

COPY ./requirements.txt .
RUN pip install -r requirements.txt

WORKDIR /simulator
COPY . ./

EXPOSE 5005/udp

CMD ["python", "-u", "src/main.py"]
\end{lstlisting}

En este Dockerfile se especifica una imagen que se utilizara como base. Estas imágenes se extraen del repositorio 
DockerHub. Después se instalan las dependencias necesarias, se expone un puerto para poder comunicarse con otros 
contenedores y por último se ejecuta el proceso correspondiente.

\subsubsection{Docker compose}

Docker-compose \cite{compose} es una herramienta diseñada para definir y ejecutar aplicaciones conformadas por varios contenedores
de Docker. Los contenedores y redes virtuales de dicha aplicación se definen en un archivo YAML, que se utilizará 
para crear, ejecutar o detener todos los contenedores con un simple comando.

\subsubsection{Nvidia-docker}

Esta herramienta \cite{nvidia-docker} desarrollada por Nvidia permite a los contenedores de Docker utilizar la GPU del sistema. Gracias
a esto se puede acelerar el entrenamiento de los modelos de manera sustancial.

\subsubsection{Python}

Python es uno de los lenguajes de programación más utilizados de forma general, y el más utilizado para aplicaciones 
de ciencia de datos y aprendizaje automático. Al ser un lenguaje interpretado no es necesario compilarlo para su ejecución, 
por lo que el proceso de despliegue del código en los contenedores de Docker se simplifica bastante.
Python puede ser descargado en \cite{python310}.

\subsubsection{InfluxDB}

InfluxDB es un sistema gestor de bases de datos para series temporales. Si bien se puede instalar de forma local,
es muy recomendable por comodidad ejecutarlo en un contenedor de Docker a partir de la imagen oficial \cite{influx:docker}.

\subsection{Contribuciones}

\subsubsection{Estructura del repositorio}
El repositorio está compuesto de dos ramas principales:
\begin{itemize}
    \item Main: la rama principal, con la última versión estable.
    \item Develop: la rama sobre la que se desarrolla.
\end{itemize}

\subsubsection{Proceso de contribución}
El proceso para contribuir y añadir nuevas características o arreglar problemas es el siguiente:
\begin{enumerate}
    \item Crear una nueva rama desde la rama ``develop''. Esta rama deberá seguir la siguiente convención de 
        nombres:
        \begin{itemize}
            \item Nueva característica: en el caso de que la contribución sea una nueva característica,
                la rama deberá llamarse ``feat/nombreCaracteristica''.
            \item Corrección de error: si la contribución es el arreglo de un error, deberá llamarse ``fix/numeroError''.
                Los números de los errores estarán definidos en el apartado Issues del repositorio de GitHub.
            \item Corrección de estilo: si la contribución es un cambio estilístico o que 
                no afecte al funcionamiento, la rama deberá llamarse ``style/nombreServicio'', utilizando el nombre 
                del servicio al que afecta.
        \end{itemize}
    \item Refactorizar hasta que pase la prueba de estilo de código.
    \item Crear la pull reques para incorporar la rama creada en develop.
\end{enumerate}

\subsubsection{Reporte de errores}
Para reportar un error, se seguirá la siguiente convención:
\begin{itemize}
    \item Título: el nombre del error queda definido como ``[BUG] Título''.
    \item Descripción: deberá añadirse una descripción breve del error, en la que deberán incluirse trazas del 
        programa y pasos para reproducir el error.
    \item Etiqueta: deberá asignarse la etiqueta de ``bug'' en el apartado ``Labels'' a la hora de crear el 
        error en GitHub.
\end{itemize}

\subsubsection{Sugerencias de nuevas características}
Las sugerencias se publicarán en el apartado de ``Issues'' del repositorio y deberán seguir el siguiente formato:
\begin{itemize}
    \item Título: el título deberá seguir el siguiente formato: ``[FEAT] Título''.
    \item Descripción: deberá contener una descripción que diga a que servicios afecta la nueva característica y 
        que ventajas supone su implementación.
\end{itemize}

\section{Compilación, instalación y ejecución del proyecto}

El primer paso para la instalación del proyecto es clonar el repositorio de GitHub mediante el siguiente comando:
\begin{lstlisting}[language=bash]
$ git clone https://github.com/gbd1004/TFG_AGV.git
\end{lstlisting}

Una vez clonado el repositorio, se procederá a la ejecución del mismo. Para la ejecución del sistema y de 
todos los servicios, utilizando la GPU para el servicio de predicción, se ejecuta el siguiente comando:
\begin{lstlisting}
$ docker compose --profile gpu up --build
\end{lstlisting}
En el caso de que se quiera ejecutar el servicio de predicción de forma que utilice la CPU, se ejecuta el 
siguiente comando:
\begin{lstlisting}
$ docker compose --profile cpu up --build
\end{lstlisting}

Se puede ejecutar también el sistema sin ejecutar el servicio de predicción. Para ello basta con no especificar 
un perfil concreto en el comando:
\begin{lstlisting}
$ docker compose up --build
\end{lstlisting}

En el caso de que quiera ejecutarse de forma desacoplada al terminal actual y sin ver los registros, se añade 
la opción ``-d'' al comando anterior.

Para detener los servicios se ha de ejecutar el siguiente comando:
\begin{lstlisting}
$ docker compose down
\end{lstlisting}

Para crear las imágenes de los contenedores de los servicios sin ejecutarlos, se introduce el siguiente comando:
\begin{lstlisting}
$ docker compose build
\end{lstlisting}

\section{Pruebas del sistema}

En este proyecto, se han realizado pruebas de forma manual debido a la complejidad y naturaleza única 
del código que se ha desarrollado. El sistema presenta características altamente personalizadas y requiere 
interacciones específicas que no son fáciles de simular en pruebas automáticas. Además, la configuración 
del entorno y las dependencias externas hacen que las pruebas automatizadas sean complicadas de implementar 
de manera efectiva.

\subsection{Pruebas realizadas}

Las siguientes pruebas han sido realizadas:
\begin{itemize}
    \item Predicciones con GPU entrenando un nuevo modelo.
    \item Predicciones con GPU usando un modelo ya entrenado.
    \item Predicciones con CPU usando un nuevo modelo.
    \item Predicciones con CPU usando un modelo ya entrenado
\end{itemize}

Para ello se inician todos los servicios como se ha visto en el apartado anterior de esta sección de los anexos.

\subsection{Mensajes de registro}

En todas las pruebas deben verse los mensajes de que los servicios ``Simulator'' (Figura \ref{fig:sim_load}) y ``Reciever'' (Figura \ref{fig:recv_load}) han cargado correctamente
y los valores mostrados concuerdan con lo especificado en los archivos de configuración.

\imagen{sim_load}{Mensaje de carga del servicio ``Simulator''}
\imagen{recv_load}{Menasaje de carga del servicio ``Reciever''}

En el caso de utilizar la versión con GPU, en los registros del sistema deberá aparecer el mensaje de que CUDA ha 
cargado correctamente (Figura \ref{fig:cuda_load}). En el caso de utilizar CPU, este mensaje no aparece en el 
registro.

\imagen{cuda_load}{Registro de CUDA}

Para los casos en los que se cargue el modelo de uno ya entrenado, se deben ver los siguientes mensajes en el registro 
(Figuras \ref{fig:wait_load} y \ref{fig:load_model})

\imagen{wait_load}{Mensaje de espera para el escalador}
\imagen{load_model}{Mensaje de carga del modelo}

En los casos en los que se entrene un nuevo modelo, aparecen los siguientes registros (Figuras \ref{fig:train_model} y \ref{fig:wait_train}).

\imagen{wait_train}{Mensaje espera para el entrenamiento}
\imagen{train_model}{Mensaje de entrenamiento del modelo}

En estos dos últimas figuras (\ref{fig:load_model} y \ref{fig:train_model}) se puede observar también si hay 
una GPU disponible para su utilización, o bien se utiliza la CPU.

Por último, por cada predicción realizada con éxito, el siguiente mensaje debería verse en los registros (Figura \ref{fig:pred_exito}).

\imagen{pred_exito}{Mensaje de éxito en la predicción}

\subsection{Visualización de los datos}

Después de que las primeras predicciones empiecen a generarse, deberían poder verse utilizando la plantilla guardada en
``services/databse/predicciones\_dashboard.json''. Para ello, se inicia sesión en la aplicación web de la base de 
datos, alojada en la dirección ``localhost:8086''. Después, se pincha en el apartado de ``Dashboards'' y dentro se 
pincha en ``Import Dashboard'', dentro de ``Create dashboard''.

Una vez importado el tablero, se puede configurar el rango temporal de los datos a visualizar, así como cada cuanto 
se refrescan las gráficas incluidas. En estos gráficos (Figura \ref{fig:preds}) deberían verse en azul los datos reales 
del AGV y en naranja las predicciones realizadas.

\imagen{preds}{Predicciones y datos reales}
