\apendice{Documentación técnica de programación}

\section{Introducción}

En este apartado del anexo se detallará la organización de los repositorios del proyecto, así
como un manual de programador, una guía de instalación y ejecución del mismo y las pruebas realizadas
al sistema.

\section{Estructura de directorios}

La organización de los directorios queda definida de la siguiente manera:

\dirtree{%
.1 memoria.
.2 build.
.2 img.
.2 tex.
}

El directorio memoria guarda todos los archivos relacionados con la memoria y estos anexos. En 
el subdirectorio build se encuentran los archivos pdf finales, en img se encuentran las imágenes 
utilizadas y en tex se guardan los archivos de LaTeX de cada uno de las secciones de la memoria y 
los anexos.

\dirtree{%
.1 prototipos.
.2 datos.
.2 forecasting.
.2 graphite.
.2 influxdb.
.2 mongo.
.2 prometheus.
.2 sqlite.
.2 timescaledb.
}

En el directorio prototipos se guardan todos los prototipos creados durante la realización del 
proyecto. Es código realizado de forma rápida con el fin de adecuarme al uso e investigar la funcionalidad
básica de cada una de las diferentes herramientas consideradas.

\dirtree{%
.1 rendimiento.
.2 database.
.2 forecast.
}

En el directorio de rendimiento se guarda todo el código de las pruebas de rendimiento realizadas 
para la comparación de las bases de datos y modelos de predicción. En el subdirectorio de 
forecast se encuentra también el código utilizado para la optimización de los hiperparámetros de 
los modelos comparados.

\dirtree{%
.1 services.
.2 forecasting.
.3 cpu.
.3 gpu.
.3 model.
.3 src.
.2 reciever.
.3 src.
.2 simulator.
.3 src.
.3 data.
}

En el directorio de servicios se encuentra todo el código y archivos de configuración de cada 
uno de los servicios desarrollados en este proyecto. El código se encuentra en el directorio
``src'' de dentro de cada uno de los subdirectorios de cada servicio. En la carpeta ``data'',
dentro del directorio del simulador, se guardan los archivos csv utilizados para leer desde 
este servicio. En los subdirectorios ``cpu'' y ``gpu'' dentro del servicio de predicción se 
encuentran los Dockerfiles de las respectivas versiones de este servicio.

\section{Manual del programador}

En esta sección se detallarán todas las dependencias necesarias para posibles futuros desarrollos, así como
los pasos necesarios para realizar dicha tarea. Este manual está pensado para el desarrollo sobre GNU/Linux,
más específicamente a cualquier distribución derivada de Debian como puede ser Ubuntu o Mint.

\subsection{Entorno de desarrollo}

Como todos los servicios se ejecutan de manera virtualizada dentro de contenedores de Docker, técnicamente las 
únicas herramientas esenciales son las siguientes:
\begin{itemize}
    \item Git: para clonar el repositorio.
    \item Docker: para crear los contenedores de cada servicio.
    \item Docker compose: para ejecutar todos los contenedores creados.
    \item Nvidia-docker: en caso de realizar el entrenamiento del modelo usando GPU.
\end{itemize}

Desarrollar de esta manera no es nada práctico, por lo que las dependencias necesarias para trabajar adecuadamente son, 
a demás de las anteriores:
\begin{itemize}
    \item Python 3.10
    \item InfluxDB 2.6.1
    \item Darts
\end{itemize}

\subsubsection{Git}

Git es necesario para poder interactuar con el repositorio, pues nos permite clonarlo, crear nuevas ramas,
subir cambios, etc. Git puede ser encontrado en \cite{git}.


\subsubsection{Docker}

Docker \cite{docker-pag} es una herramienta que permite ejecutar procesos en contenedores. Un contenedor es un proceso aislado del 
resto del sistema, similar a una máquina virtual. Para ello, se crea lo que se conoce como imagen, que es una especie 
de plantilla del contenedor. Esta imagen contiene el sistema de ficheros del contenedor y todas las dependencias 
necesarias para ejecutar los procesos de este.

Gracias a esto, conseguimos que el sistema sea portable, pudiendo ser ejecutado en cualquier sistema que soporte 
Docker. Gracias también a Docker se simplifica mucho el despliegue del sistema, pues todas las dependencias 
se instalan en el sistema de ficheros especificado en la imagen.

Para definir estas imágenes se utiliza un archivo llamado ``Dockerfile''. Por ejemplo, este es el Dockerfile del 
servicio simulador:
\begin{lstlisting}
FROM python:3

COPY ./requirements.txt .
RUN pip install -r requirements.txt

WORKDIR /simulator
COPY . ./

EXPOSE 5005/udp

CMD ["python", "-u", "src/main.py"]
\end{lstlisting}

En este Dockerfile se especifica una imagen que se utilizara como base. Estas imágenes se extraen del repositorio 
DockerHub. Después se instalan las dependencias necesarias, se expone un puerto para poder comunicarse con otros 
contenedores y por último se ejecuta el proceso correspondiente.

\subsubsection{Docker compose}

Docker-compose \cite{compose} es una herramienta diseñada para definir y ejecutar aplicaciones conformadas por varios contenedores
de Docker. Los contenedores y redes virtuales de dicha aplicación se definen en un archivo YAML, que se utilizará 
para crear, ejecutar o detener todos los contenedores con un simple comando.

\subsubsection{Nvidia-docker}

Esta herramienta \cite{nvidia-docker} desarrollada por Nvidia permite a los contenedores de Docker utilizar la GPU del sistema. Gracias
a esto se puede acelerar el entrenamiento de los modelos de manera sustancial.

\subsubsection{Python}

Python es uno de los lenguajes de programación más utilizados de forma general, y el más utilizado para aplicaciones 
de ciencia de datos y aprendizaje automático. Al ser un lenguaje interpretado no es necesario compilarlo para su ejecución, 
por lo que el proceso de despliegue del código en los contenedores de Docker se simplifica bastante.
Python puede ser descargado en \cite{python310}.

\subsubsection{InfluxDB}

InfluxDB es un sistema gestor de bases de datos para series temporales. Si bien se puede instalar de forma local,
es muy recomendable por comodidad ejecutarlo en un contenedor de Docker a partir de la imagen oficial \cite{influx:docker}.

\subsection{Contribuciones}
% TODO GUIA DE AÑADIR NUEVAS FEATURES

\section{Compilación, instalación y ejecución del proyecto}

El primer paso para la instalación del proyecto es clonar el repositorio de GitHub mediante el siguiente comando:
\begin{lstlisting}[language=bash]
$ git clone https://github.com/gbd1004/TFG_AGV.git
\end{lstlisting}

Una vez clonado el repositorio, se procederá a la ejecución del mismo. Para la ejecución del sistema y de 
todos los servicios, utilizando la GPU para el servicio de predicción, se ejecuta el siguiente comando:
\begin{lstlisting}
$ docker compose --profile gpu up --build
\end{lstlisting}
En el caso de que se quiera ejecutar el servicio de predicción de forma que utilice la CPU, se ejecuta el 
siguiente comando:
\begin{lstlisting}
$ docker compose --profile cpu up --build
\end{lstlisting}

Se puede ejecutar también el sistema sin ejecuar el servicio de predicción. Para ello basta con no especificar 
un perfil concreto en el comando:
\begin{lstlisting}
$ docker compose up --build
\end{lstlisting}

En el caso de que quiera ejecutarse de forma desacoplada al terminal actual y sin ver los registros, se añade 
la opción ``-d'' al comando anterior.

Para detener los servicios se ha de ejecutar el siguiente comando:
\begin{lstlisting}
$ docker compose down
\end{lstlisting}

\section{Pruebas del sistema}

% TODO