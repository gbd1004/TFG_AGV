\apendice{Documentación de usuario}

\section{Introducción}

Este manual detalla los requisitos desde el punto de vista del usuario, así como la guía de instalación y 
un manual del funcionamiento del proyecto.

\section{Requisitos de usuarios}

\subsection*{Requisitos de hardware}
Como ya ha sido mencionado con anterioridad, es muy recomendable utilizar la GPU para acelerar la predicción de 
los datos. Para ello, se necesita una GPU con soporte para CUDA 11.8 o superior. Dicha compatibilidad puede
comprobarse en \cite{cuda-compatibility}.

El otro elemento que necesita de un buen rendimiento es la base de datos. Un hardware insuficiente puede suponer 
retrasos a la hora de insertar nuevos datos e incluso cuelgues del sistema, por lo que los requisitos mínimos de 
hardware irán dictados en gran medida por dicho servicio. Según la documentación de InfluxDB \cite{influx:requirements}, para nuestras necesidades 
estimadas se necesita de una CPU de 2 a 4 núcleos y de 2 a 5 GB de memoria RAM. Un disco SSD también es muy recomendado.

\subsection*{Requisitos de software}
Para la ejecución del proyecto las únicas herramientas necesarias son Docker \cite{docker-pag} y docker-compose \cite{compose}.
En cuanto al sistema operativo, el proyecto puede ejecutarse en cualquier sistema operativo que soporte estas aplicaciones.

En el caso de querer usar la versión del servicio de predicción que utiliza la GPU, es necesario también instalar 
nvidia-docker \cite{nvidia-docker}. Esta herramienta solo funciona en Linux, por lo que este es el único sistema 
operativo soportado para este caso.

\section{Instalación}

El primer paso para instalar el proyecto es clonar el repositorio con el siguiente comando:
\begin{lstlisting}[language=bash]
$ git clone https://github.com/gbd1004/TFG_AGV.git
\end{lstlisting}
Después de clonar el repositorio se navega a la carpeta ``services'' y se ejecuta el siguiente 
comando para construir las imágenes de los contenedores de cada servicio:
\begin{lstlisting}[language=bash]
$ docker-compose build
\end{lstlisting}

Una vez ejecutados estos comandos tendremos el proyecto listo para ejecutarse.

\section{Manual del usuario}

\subsection{Ejecución del proyecto}

Para ejecutar el proyecto se utiliza el siguiente comando desde la carpeta ``services'':
\begin{lstlisting}[language=bash]
$ docker-compose up --build
\end{lstlisting}
La opción ``--build'' construye las imágenes de los contenedores en caso de que algo haya cambiado o 
no se haya ejecutado el paso anterior.

Opcionalmente se puede añadir también el argumento ``-d'' en caso de que se quiera ejecutar desacoplado 
del terminal actual.

Para detener la ejecución del proyecto se ejecuta el siguiente comando:
\begin{lstlisting}[language=bash]
$ docker-compose down
\end{lstlisting}
Se puede añadir también el argumento ``-v'' en caso de que queramos eliminar los volúmenes montados 
en los contenedores.

\subsection{Archivos de configuración}

Cada servicio cuenta con sus archivos de configuración. A continuación se detallan los elementos 
de cada uno de ellos.

\subsubsection{Database}
El archivo de configuración de la base de datos se encuentra en el directorio ``./services/database'' 
y se llama ``influxdb\_credentials.env''. Este archivo de variables de entorno se carga en el servicio 
de la base de datos y en todos los servicios que tengan conexión con dicha la base de datos.

El contenido es el siguiente:
\begin{itemize}
    \item DOCKER\_INFLUXDB\_INIT\_USERNAME: Nombre de usuario utilizado para iniciar sesión en la aplicación web.
    \item DOCKER\_INFLUXDB\_INIT\_PASSWORD: Contraseña del usuario del sistema.
    \item DOCKER\_INFLUXDB\_INIT\_ADMIN\_TOKEN: Token de seguridad del usuario administrador, y que tiene permisos 
        de escritura en la base de datos.
    \item DOCKER\_INFLUXDB\_INIT\_ORG: Nombre de la organización en la que se crean los ``buckets'' y usuarios de
        la base de datos.
    \item DOCKER\_INFLUXDB\_INIT\_BUCKET: Nombre del ``bucket'' en el que se insertan los datos del AGV o del simulador.
    \item DOCKER\_INFLUXDB\_INIT\_MODE: Modo en el que se inicia la base de datos.
\end{itemize}
De todos estos campos, el único que no es configurable es el último, pues sin este valor la base de datos 
no se cargará correctamente.

\subsubsection{Forecasting}

Tanto la versión con GPU de este servicio como la versión que usa CPU siguen la misma estructura 
y tienen los mismos archivos de configuración. Estos se encuentran en la carpeta base de cada servicio,
``./services/forecasting\_gpu'' para el caso que utiliza la GPU y ``./services/forecasting\_cpu'' para 
el caso que utiliza la CPU. 

En ambos casos, el archivo de configuración se llama ``config.json'' y contiene los siguientes campos:
\begin{itemize}
    \item load\_model: guarda un valor booleano. En caso de ser ``true'' el servicio carga el modelo a entrenar.
        Por contra, si el valor es ``false'' el modelo se entrenará en la ejecución del servicio.
    \item model\_file: nombre del modelo a cargar. Es también el nombre que tendrá el modelo guardado cuando 
        en el caso de que se entrene en vez de cargarlo.
    \item wait\_time\_before\_train: tiempo a esperar antes de entrenar para dar tiempo a que haya datos que 
        utilizar en la base de datos para dicho entrenamiento. Cuanto más alto sea este valor, más preciso será 
        el modelo, pero también más tiempo tardará en entrenarse.
    \item wait\_time\_before\_load: tiempo a esperar antes de cargar el modelo para poder ajustar el escalador de los
        datos. Los datos necesitan escalarse, ya que el modelo de predicciones espera valores entre 0 y 1.
\end{itemize}

En el caso de que quiera utilizarse la GPU para acelerar el entrenamiento de los datos, el servicio de predicción tendrá 
que configurarse de la siguiente manera en dicho archivo ``docker-compose.yml''.
\begin{lstlisting}
forecasting:
  build: forecasting_gpu/.
  env_file:
    - database/influxdb_credentials.env
  volumes:
    - ./forecasting_gpu/model:/forecasting_gpu/model
  deploy:
    resources:
      reservations:
        devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
\end{lstlisting}

Por otra parte, si no pretende usarse la GPU o no se dispone de una compatible, y por tanto se quiere usar la 
CPU para entrenar los modelos, el servicio de predicción se especifica de la siguiente manera:
\begin{lstlisting}
forecasting:
  build: forecasting_cpu/.
  env_file:
    - database/influxdb_credentials.env
  volumes:
    - ./forecasting_cpu/model:/forecasting_cpu/model
\end{lstlisting}

\subsubsection{Reciever}

El archivo de configuración para este servicio se encuentra en el directorio ``./services/reciever'' y 
contiene solo un único campo:
\begin{itemize}
    \item max\_retries: reintentos máximos que realizara este servicio en caso de que la conexión con 
        la base de datos falle al iniciar este proceso.
\end{itemize}

\subsubsection{Simulator}

% TODO